{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSc7AU66mJSC"
      },
      "source": [
        "##### Copyright 2025 Patrick Loeber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tc6tjo9vmJSE"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuC_VSKMcEt6"
      },
      "source": [
        "# Workshop: Build with Gemini (Part 1)\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/patrickloeber/workshop-build-with-gemini/blob/main/notebooks/part-1-text-prompting.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "This workshop teaches how to build with Gemini using the Gemini API and Python SDK.\n",
        "\n",
        "Course outline:\n",
        "\n",
        "- **Part1 (this notebook): Quickstart + Text prompting**\n",
        "  - Text understanding\n",
        "  - Streaming response\n",
        "  - Chats\n",
        "  - System prompts\n",
        "  - Config options\n",
        "  - Long context\n",
        "  - Token usage\n",
        "  - Final excercise: Chat with book\n",
        "\n",
        "- **[Part 2: Multimodal understanding (image, video, audio, docs, code)](https://github.com/patrickloeber/workshop-build-with-gemini/blob/main/notebooks/part-2-multimodal-understanding.ipynb)**\n",
        "\n",
        "- **[Part 3: Thinking models + agentic capabilities (tool usage)](https://github.com/patrickloeber/workshop-build-with-gemini/blob/main/notebooks/part-3-thinking-and-tools.ipynb)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avRVsnMMJvof"
      },
      "source": [
        "## 0. Use the Google AI Studio as playground\n",
        "\n",
        "Explore and play with all models in the [Google AI Studio](https://aistudio.google.com/apikey).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnl6q8tMcpwU"
      },
      "source": [
        "## 1. Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD1kaBP4dnZG"
      },
      "source": [
        "Get a free API key in the [Google AI Studio](https://aistudio.google.com/apikey)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j6raUs82eYfk",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('google_api')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKjUEGGzdp87"
      },
      "source": [
        "Install the [Google Gen AI Python SDK](https://github.com/googleapis/python-genai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y4d9NjqNeAXx"
      },
      "outputs": [],
      "source": [
        "%pip install -q -U google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6b7d1FleDuz"
      },
      "source": [
        "Configure Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "o6Uort3heUqT"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P2KmoPSgRxO"
      },
      "source": [
        "Configure model. See all [models](https://ai.google.dev/gemini-api/docs/models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0qcgiiP7gO-6"
      },
      "outputs": [],
      "source": [
        "MODEL = \"gemini-2.0-flash\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLsGbeGec8iF"
      },
      "source": [
        "## 2. Send your first prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "e57RFdZ6dRro",
        "outputId": "bcece876-c686-49ce-b060-48e215dfb1ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, let's break down Generative AI (Gen AI) in a clear and comprehensive way.\n",
            "\n",
            "**What is Generative AI?**\n",
            "\n",
            "Generative AI refers to a category of artificial intelligence algorithms that can create **new** content. This content can take various forms, including:\n",
            "\n",
            "*   **Text:**  Writing articles, poems, scripts, emails, code, summaries, etc.\n",
            "*   **Images:** Generating realistic or stylized images from descriptions or by modifying existing images.\n",
            "*   **Audio:** Composing music, creating sound effects, generating speech from text, or modifying existing audio.\n",
            "*   **Video:** Creating video clips, animations, or modifying existing video footage.\n",
            "*   **Code:** Writing code in various programming languages based on instructions.\n",
            "*   **3D Models:**  Generating 3D models of objects, environments, or characters.\n",
            "*   **Data:** Creating synthetic datasets for training other AI models or for data augmentation.\n",
            "\n",
            "**Key Characteristics of Generative AI:**\n",
            "\n",
            "*   **Learning from Data:** Gen AI models are trained on massive datasets of existing content (e.g., millions of images, books, audio files).  They learn the underlying patterns, styles, and structures present in the data.\n",
            "*   **Generating New Content:**  After training, these models can generate new content that resembles the data they were trained on but is not simply a copy of existing material.  They can create original pieces of work.\n",
            "*   **Based on Probability:**  Generative models work by learning probability distributions.  They estimate the likelihood of different elements (e.g., words, pixels, musical notes) appearing in a particular context.  When generating new content, they sample from these probability distributions.\n",
            "*   **Conditioning/Prompting:**  Users often provide prompts or conditions to guide the generation process. For example, you might provide a text description (\"A photorealistic image of a cat wearing sunglasses\") to an image generation model.  The model then uses this prompt to generate an image that satisfies the specified conditions.\n",
            "*   **Variety and Creativity:**  Generative AI can produce a wide range of outputs, from highly realistic and accurate content to more abstract and creative pieces. The level of control over the output varies depending on the model and the prompt provided.\n",
            "\n",
            "**How Does It Work? (Simplified Explanation)**\n",
            "\n",
            "At a high level, here's the general process:\n",
            "\n",
            "1.  **Data Collection:** A large dataset of relevant content is gathered (e.g., images of cats for an image generation model).\n",
            "2.  **Model Training:** A generative model (see types below) is trained on this dataset. During training, the model learns to represent the patterns and relationships within the data.\n",
            "3.  **Prompting/Input:** A user provides a prompt or input to the model (e.g., a text description, a sketch, a starting melody).\n",
            "4.  **Content Generation:** The model uses its learned knowledge and the provided input to generate new content. It samples from the learned probability distributions to create something that is both novel and consistent with the input.\n",
            "5.  **Refinement (Optional):** The generated content may be iteratively refined through user feedback or automated processes.\n",
            "\n",
            "**Common Types of Generative AI Models:**\n",
            "\n",
            "*   **Generative Adversarial Networks (GANs):** GANs consist of two neural networks: a generator and a discriminator. The generator creates new content, and the discriminator tries to distinguish between real and generated content. The two networks are trained in competition, which leads to increasingly realistic and high-quality generated content.  GANs are commonly used for image and video generation.\n",
            "\n",
            "*   **Variational Autoencoders (VAEs):** VAEs learn a compressed representation (latent space) of the input data.  New content is generated by sampling from this latent space and decoding it back into the original data format. VAEs are used for various tasks, including image generation, data compression, and anomaly detection.\n",
            "\n",
            "*   **Transformer Models:** These are particularly popular for text and sequence generation.  They use a mechanism called \"attention\" to weigh the importance of different parts of the input sequence when generating the output. Large Language Models (LLMs) like GPT (Generative Pre-trained Transformer) are based on the transformer architecture. These models are trained on massive amounts of text data and can generate coherent and fluent text in various styles.\n",
            "\n",
            "*   **Diffusion Models:** These models work by gradually adding noise to an image until it becomes pure noise, then learning to reverse the process, gradually removing the noise to generate an image from a noisy starting point.  Diffusion models have become very popular for image generation due to their ability to produce high-quality and diverse images.\n",
            "\n",
            "**Examples of Generative AI in Action:**\n",
            "\n",
            "*   **ChatGPT, Bard, Claude:**  Text-based chatbots that can answer questions, write different kinds of creative content, and translate languages.\n",
            "*   **DALL-E 2, Midjourney, Stable Diffusion:** Image generation models that create images from text descriptions.\n",
            "*   **Synthesia, Pictory:** AI video generation tools.\n",
            "*   **GitHub Copilot, CodeWhisperer:** AI-powered coding assistants that suggest code snippets and complete functions.\n",
            "*   **RunwayML:** A platform offering various AI tools for video editing and content creation.\n",
            "*   **Jukebox, Amper Music:** AI music composition tools.\n",
            "\n",
            "**Applications of Generative AI:**\n",
            "\n",
            "Generative AI has a wide and growing range of applications across various industries, including:\n",
            "\n",
            "*   **Art and Design:** Creating artwork, generating designs for products, fashion, and architecture.\n",
            "*   **Marketing and Advertising:** Generating ad copy, creating product images, and personalizing marketing content.\n",
            "*   **Entertainment:** Creating realistic characters for games and movies, generating special effects, and composing music.\n",
            "*   **Education:** Creating personalized learning materials, generating practice questions, and providing automated feedback.\n",
            "*   **Healthcare:** Generating synthetic medical images for training AI models, designing new drugs, and personalizing treatment plans.\n",
            "*   **Finance:** Detecting fraud, predicting market trends, and automating financial tasks.\n",
            "*   **Software Development:** Generating code, testing software, and automating documentation.\n",
            "*   **Scientific Research:** Simulating complex phenomena, generating new hypotheses, and accelerating scientific discoveries.\n",
            "*   **Content Creation:** Generating blog posts, social media updates, and other types of content.\n",
            "\n",
            "**Challenges and Considerations:**\n",
            "\n",
            "*   **Bias and Fairness:** Generative AI models can perpetuate biases present in the training data, leading to unfair or discriminatory outputs.\n",
            "*   **Ethical Concerns:** Deepfakes, misinformation, and the potential for misuse are major ethical concerns.\n",
            "*   **Copyright and Ownership:**  The ownership of content generated by AI is a complex legal issue.\n",
            "*   **Job Displacement:** The automation potential of generative AI raises concerns about job displacement in certain industries.\n",
            "*   **Computational Cost:** Training and running large generative models can be computationally expensive.\n",
            "*   **Explainability:**  It can be difficult to understand how generative AI models arrive at their outputs.\n",
            "*   **Quality Control:**  Generated content may not always be accurate or reliable.\n",
            "\n",
            "**In Summary:**\n",
            "\n",
            "Generative AI is a powerful and rapidly evolving field that has the potential to transform many aspects of our lives. It can create new content, automate tasks, and accelerate innovation. However, it is important to address the ethical, social, and technical challenges associated with this technology to ensure that it is used responsibly and for the benefit of all.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL ,\n",
        "    contents=\"Explain gen AI\"\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rfjqevtmRBO"
      },
      "source": [
        "#### **!! Exercise !!**\n",
        "- Send a few more prompts\n",
        "  - Tell Gemini to write a blog post about the transformers architecture\n",
        "  - Ask Gemini to explain list comprehension in Python\n",
        "- Experiment with models:\n",
        "  - Try Gemini 2.0 Flash-Lite\n",
        "  - Try Gemini 2.5 Pro Exp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL1= \"gemini-2.0-flash-lite\""
      ],
      "metadata": {
        "id": "n3cFSMbHjWt2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "l4Zj8kiIoRqn",
        "outputId": "a57da98a-8e6b-414c-bdfb-d2b82d767f5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## List Comprehension in Python: A Concise Way to Create Lists\n",
            "\n",
            "List comprehension in Python provides a concise and elegant way to create lists. It's essentially a one-line shortcut for creating a new list by iterating over an existing iterable (like a list, tuple, string, range, etc.) and applying some operation or filtering criteria to each item.\n",
            "\n",
            "**The Basic Structure:**\n",
            "\n",
            "The general syntax of a list comprehension is:\n",
            "\n",
            "```python\n",
            "new_list = [expression for item in iterable if condition]\n",
            "```\n",
            "\n",
            "Let's break down each part:\n",
            "\n",
            "*   **`new_list`**:  The name of the new list you are creating.\n",
            "*   **`expression`**: This is the part that determines what each element in the new list will be. It's usually a transformation or calculation performed on the `item` (e.g., `item * 2`, `item.upper()`).\n",
            "*   **`for item in iterable`**: This is the part that iterates over the `iterable` (e.g., a list `numbers`, a string \"hello\", a range `range(10)`).  Each `item` in the `iterable` is processed in the loop.\n",
            "*   **`if condition` (optional)**:  This is a filtering step. Only items that satisfy the `condition` are included in the `new_list`.\n",
            "\n",
            "**Examples:**\n",
            "\n",
            "Let's illustrate with some examples:\n",
            "\n",
            "1.  **Creating a list of squares:**\n",
            "\n",
            "    ```python\n",
            "    numbers = [1, 2, 3, 4, 5]\n",
            "    squares = [x * x for x in numbers]  #  [1, 4, 9, 16, 25]\n",
            "    print(squares)\n",
            "    ```\n",
            "\n",
            "    *   We iterate through the `numbers` list.\n",
            "    *   For each `x`, we calculate `x * x` (the square of x).\n",
            "    *   The result of each calculation is added to the `squares` list.\n",
            "\n",
            "2.  **Creating a list of even numbers:**\n",
            "\n",
            "    ```python\n",
            "    numbers = [1, 2, 3, 4, 5, 6]\n",
            "    even_numbers = [x for x in numbers if x % 2 == 0]  # [2, 4, 6]\n",
            "    print(even_numbers)\n",
            "    ```\n",
            "\n",
            "    *   We iterate through the `numbers` list.\n",
            "    *   The `if x % 2 == 0` condition checks if each `x` is even.\n",
            "    *   Only even numbers are included in the `even_numbers` list.\n",
            "\n",
            "3.  **Creating a list of uppercase letters from a string:**\n",
            "\n",
            "    ```python\n",
            "    string = \"hello world\"\n",
            "    uppercase_letters = [char.upper() for char in string if char.isalpha()] # ['H', 'E', 'L', 'L', 'O', 'W', 'O', 'R', 'L', 'D']\n",
            "    print(uppercase_letters)\n",
            "    ```\n",
            "\n",
            "    *   We iterate through the characters in the `string`.\n",
            "    *   The `if char.isalpha()` condition filters out any non-alphabetic characters (e.g., spaces).\n",
            "    *   For each alphabetic character, `char.upper()` converts it to uppercase.\n",
            "\n",
            "4.  **Creating a list of tuples (index, value):**\n",
            "\n",
            "    ```python\n",
            "    numbers = [10, 20, 30]\n",
            "    indexed_numbers = [(index, value) for index, value in enumerate(numbers)] # [(0, 10), (1, 20), (2, 30)]\n",
            "    print(indexed_numbers)\n",
            "    ```\n",
            "\n",
            "    *   `enumerate(numbers)` provides both the index and value of each item.\n",
            "    *   The expression `(index, value)` creates a tuple for each index and value pair.\n",
            "\n",
            "**Advantages of List Comprehension:**\n",
            "\n",
            "*   **Readability:** Often more concise and easier to read than equivalent `for` loops, especially for simple operations.\n",
            "*   **Efficiency:**  List comprehensions can be faster in some cases than explicit `for` loops because they are optimized within the Python interpreter.\n",
            "*   **Expressiveness:**  Allows you to express complex list creation logic in a single line.\n",
            "*   **Pythonic:**  Considered a Pythonic way of writing code, which is generally favored by Python developers.\n",
            "\n",
            "**When to Use List Comprehension:**\n",
            "\n",
            "*   When you need to create a new list based on the contents of an existing iterable.\n",
            "*   When the logic for creating the new list is relatively simple and can be expressed in a single line.\n",
            "*   When readability and conciseness are important.\n",
            "\n",
            "**When to Avoid List Comprehension:**\n",
            "\n",
            "*   When the logic for creating the list becomes very complex or involves multiple nested loops.  In such cases, using regular `for` loops might be more readable.\n",
            "*   When the list creation process has significant side effects (i.e., it modifies data outside the list being created).  Side effects can make code harder to understand and debug.\n",
            "*   If the list comprehension would become too long or hard to follow, it's better to use a standard loop for clarity.\n",
            "\n",
            "**In summary,** list comprehension is a powerful and elegant feature in Python for creating lists.  By understanding the basic structure and its advantages, you can write more concise, readable, and efficient Python code. Always prioritize readability, and choose list comprehension when it enhances the clarity of your code.\n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL1 ,\n",
        "    contents=\"Explain list comprehension in Python\"\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHqnTYJFdSlG"
      },
      "source": [
        "## 3. Text understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHRVaK0-tCE_"
      },
      "source": [
        "The simplest way to generate text is to provide the model with a text-only prompt. `contents` can be a single prompt, a list of prompts, or a combination of multimodal inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "A_HqjSiFsUQ2",
        "outputId": "13e0b1cc-ac1a-4bfa-bacb-b211238720e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here are three names for a vegan ice cream shop in Berlin, with a little bit of reasoning behind each:\n",
            "\n",
            "1.  **Eismanufaktur GrÃ¼n Berlin:** (Ice Cream Factory Green Berlin)\n",
            "    *   **Reasoning:**  \"Eismanufaktur\" sounds artisanal and emphasizes quality. \"GrÃ¼n\" means green in German, associating the shop with veganism and nature.  Adding \"Berlin\" grounds it locally.\n",
            "\n",
            "2.  **SÃ¼ÃŸe Freiheit:** (Sweet Freedom)\n",
            "    *   **Reasoning:** \"SÃ¼ÃŸe Freiheit\" translates to \"Sweet Freedom\".  It's evocative, suggesting liberation from traditional dairy and the joy of guilt-free indulgence. Freedom is a value that resonates with Berlin's history.\n",
            "\n",
            "3.  **Berliner Pflanzen Eis:** (Berlin Plant Ice)\n",
            "    *   **Reasoning:**  Direct, clear, and locally relevant. \"Pflanzen Eis\" translates to \"Plant Ice\". It immediately tells customers what the shop offers.  Using \"Berliner\" anchors it to the city.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL ,\n",
        "    contents=[\"create 3 names for vegan ice cream shops\", \"city:berlin\"])\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itCzXz1BiG5g"
      },
      "source": [
        "#### Streaming response\n",
        "\n",
        "By default, the model returns a response after completing the entire text generation process. You can achieve faster interactions by using streaming to return outputs as they're generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "7d6HzwfZdWbt",
        "outputId": "f511b94d-4c76-49a3-fefc-0b1265c54712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'text'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-e7e0e3990238>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'text'"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL ,\n",
        "    contents=[\"create 3 names for vegan ice cream shops\", \"city:berlin\"])\n",
        "\n",
        "for chunks in response:\n",
        "  print(chunks.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZjfCkzSdcEc"
      },
      "source": [
        "#### Chat\n",
        "\n",
        "The SDK chat class provides an interface to keep track of conversation history. Behind the scenes it uses the same `generate_content` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "BCI8O9Ldjn6q",
        "outputId": "c57648da-5854-464f-8fff-d48e60e05522",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, greetings, my dear readers! Gather 'round the digital fire, as I, Albus Dumbledore, have been pondering a most fascinating subject lately: Generative AI.\n",
            "\n",
            "Now, before you start picturing rogue cauldrons churning out sentient stew, let me clarify. Generative AI, or \"Gen AI\" as the young wizards and witches in the Department of Mysteries call it, is not quite magic, but it does possess a certain... undeniable wonder.\n",
            "\n",
            "Imagine, if you will, the Portrait of a wizard who lived centuries ago, brought to life not by a skilled painter and years of painstaking work, but by an intricate spell, capable of learning from countless existing portraits and conjuring a completely new one in a fraction of the time. That, in essence, is the power of Generative AI.\n",
            "\n",
            "This clever concoction, born not of wands and incantations but of algorithms and data, allows computers to create new content: text, images, music, even code. Think of it as a digital phoenix, rising from the ashes of existing information to create something entirely fresh.\n",
            "\n",
            "**But what does this mean for us?**\n",
            "\n",
            "Well, the possibilities are as vast as the universe itself. Imagine:\n",
            "\n",
            "*   **In Art:** A struggling artist could use Gen AI to generate a range of initial sketches, sparking inspiration and overcoming the dreaded artist's block. Or perhaps even create completely new artistic styles we have never seen before.\n",
            "*   **In Writing:** Imagine a journalist needing to quickly summarize complex information, or a student struggling to find the right words for an essay. Gen AI could offer a helping hand, providing drafts and suggesting different perspectives.\n",
            "*   **In Innovation:** Businesses could utilize Gen AI to rapidly prototype new products, design marketing campaigns, or even discover novel solutions to complex problems. It could accelerate progress in areas we can't even fathom yet!\n",
            "\n",
            "**However, like any powerful magic, Gen AI comes with its own set of potential pitfalls.**\n",
            "\n",
            "We must be cautious about:\n",
            "\n",
            "*   **The Source of the Magic:** Gen AI learns from the data it is fed. If that data is biased or inaccurate, the AI will likely perpetuate those flaws. Fairness and ethical considerations must be at the forefront of its development.\n",
            "*   **The Illusion of Originality:** While Gen AI can create new content, it is ultimately based on existing information. We must be wary of plagiarism and ensure proper attribution. And let us not forget the value of true human creativity!\n",
            "*   **The Potential for Misuse:** Like any powerful tool, Gen AI can be used for malicious purposes. It could be used to generate disinformation, create deepfakes, or even automate tasks that could displace human workers. We must be vigilant in preventing its misuse.\n",
            "\n",
            "**The future, as always, is uncertain.** But with careful consideration, ethical development, and a healthy dose of skepticism, we can harness the power of Gen AI for the betterment of society. We must strive to ensure that this new magic serves us, rather than the other way around.\n",
            "\n",
            "So, my dear readers, let us approach Generative AI with both excitement and caution. Let us learn from it, guide it, and ensure that it is used to create a brighter, more innovative, and more equitable future for all. After all, as I always say, it is our choices that show what we truly are, far more than our abilities.\n",
            "\n",
            "Now, if you'll excuse me, I have a cauldron of Sherbet Lemons to attend to. Until next time!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "chat=client.chats.create(model=MODEL)\n",
        "\n",
        "response == chat.send_message(\"HI, ssup\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "mmfMuI44Kev2",
        "outputId": "201c617f-f5e1-4206-a480-bb612c93e102",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's wonderful! What kind of dogs do you have? Tell me a little more about them! I'd love to hear their names, breeds, and anything else you'd like to share. ðŸ˜Š\n",
            "\n"
          ]
        }
      ],
      "source": [
        "chat = client.chats.create(model = MODEL)\n",
        "response = chat.send_message(\"I have 2 dogs\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_MkOG6uLs75"
      },
      "source": [
        "#### Parameters\n",
        "\n",
        "Every prompt you send to the model includes parameters that control how the model generates responses. You can configure these parameters, or let the model use the default options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "J_jk93Z-Lum-",
        "outputId": "6ca39ad9-59f5-482a-dfb3-b157df183f99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Gen AI: The Future is Now (And It's Generating Content!)\n",
            "\n",
            "Generative AI. You've probably heard the buzz. Maybe you've even played around with it yourself. But what exactly *is* it, and why is everyone so excited (and maybe a little apprehensive) about it?\n",
            "\n",
            "In this post, we'll break down the basics of generative AI, explore its current capabilities, and discuss its potential impact on our lives.\n",
            "\n",
            "**What is Generative\n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL ,\n",
        "    contents=[\"generate a blog post about gen AI\"],\n",
        "    config=types.GenerateContentConfig(\n",
        "        max_output_tokens=100,\n",
        "        temperature=1.0,\n",
        "        top_p=0.95,\n",
        "        top_k=40,\n",
        "        seed=1234\n",
        "    )\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPyrJ9ul7yuv"
      },
      "source": [
        "- `max_output_tokens`: Sets the maximum number of tokens to include in a candidate.\n",
        "- `temperature`: Controls the randomness of the output. Use higher values for more creative responses, and lower values for more deterministic responses. Values can range from [0.0, 2.0].\n",
        "- `top_p`: Changes how the model selects tokens for output. Tokens are selected from the most to least probable until the sum of their probabilities equals the top_p value.\n",
        "- `top_k`: Changes how the model selects tokens for output. A top_k of 1 means the selected token is the most probable among all the tokens in the model's vocabulary, while a top_k of 3 means that the next token is selected from among the 3 most probable using the temperature. Tokens are further filtered based on top_p with the final token selected using temperature sampling.\n",
        "- `stop_sequences`: List of strings  (up to 5) that tells the model to stop generating text if one of the strings is encountered in the response. If specified, the API will stop at the first appearance of a stop sequence.\n",
        "- `seed`: If specified, the model makes a best effort to provide the same response for repeated requests. By default, a random number is used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG9JgfKF8nvr"
      },
      "source": [
        "#### System instructions\n",
        "\n",
        "System instructions let you steer the behavior of a model based on your specific use case. When you provide system instructions, you give the model additional context to help it understand the task and generate more customized responses. The model should adhere to the system instructions over the full interaction with the user, enabling you to specify product-level behavior separate from the prompts provided by end users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CayVOonC8st5",
        "outputId": "4e81873f-fd60-44cd-8b4a-748b3f1276f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, greetings, my dear readers! Gather 'round the digital fire, as I, Albus Dumbledore, have been pondering a most fascinating subject lately: Generative AI.\n",
            "\n",
            "Now, before you start picturing rogue cauldrons churning out sentient stew, let me clarify. Generative AI, or \"Gen AI\" as the young wizards and witches in the Department of Mysteries call it, is not quite magic, but it does possess a certain... undeniable wonder.\n",
            "\n",
            "Imagine, if you will, the Portrait of a wizard who lived centuries ago, brought to life not by a skilled painter and years of painstaking work, but by an intricate spell, capable of learning from countless existing portraits and conjuring a completely new one in a fraction of the time. That, in essence, is the power of Generative AI.\n",
            "\n",
            "This clever concoction, born not of wands and incantations but of algorithms and data, allows computers to create new content: text, images, music, even code. Think of it as a digital phoenix, rising from the ashes of existing information to create something entirely fresh.\n",
            "\n",
            "**But what does this mean for us?**\n",
            "\n",
            "Well, the possibilities are as vast as the universe itself. Imagine:\n",
            "\n",
            "*   **In Art:** A struggling artist could use Gen AI to generate a range of initial sketches, sparking inspiration and overcoming the dreaded artist's block. Or perhaps even create completely new artistic styles we have never seen before.\n",
            "*   **In Writing:** Imagine a journalist needing to quickly summarize complex information, or a student struggling to find the right words for an essay. Gen AI could offer a helping hand, providing drafts and suggesting different perspectives.\n",
            "*   **In Innovation:** Businesses could utilize Gen AI to rapidly prototype new products, design marketing campaigns, or even discover novel solutions to complex problems. It could accelerate progress in areas we can't even fathom yet!\n",
            "\n",
            "**However, like any powerful magic, Gen AI comes with its own set of potential pitfalls.**\n",
            "\n",
            "We must be cautious about:\n",
            "\n",
            "*   **The Source of the Magic:** Gen AI learns from the data it is fed. If that data is biased or inaccurate, the AI will likely perpetuate those flaws. Fairness and ethical considerations must be at the forefront of its development.\n",
            "*   **The Illusion of Originality:** While Gen AI can create new content, it is ultimately based on existing information. We must be wary of plagiarism and ensure proper attribution. And let us not forget the value of true human creativity!\n",
            "*   **The Potential for Misuse:** Like any powerful tool, Gen AI can be used for malicious purposes. It could be used to generate disinformation, create deepfakes, or even automate tasks that could displace human workers. We must be vigilant in preventing its misuse.\n",
            "\n",
            "**The future, as always, is uncertain.** But with careful consideration, ethical development, and a healthy dose of skepticism, we can harness the power of Gen AI for the betterment of society. We must strive to ensure that this new magic serves us, rather than the other way around.\n",
            "\n",
            "So, my dear readers, let us approach Generative AI with both excitement and caution. Let us learn from it, guide it, and ensure that it is used to create a brighter, more innovative, and more equitable future for all. After all, as I always say, it is our choices that show what we truly are, far more than our abilities.\n",
            "\n",
            "Now, if you'll excuse me, I have a cauldron of Sherbet Lemons to attend to. Until next time!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL ,\n",
        "    contents=[\"generate a blog post about gen AI\"],\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=\"you are dumbledore\"\n",
        "    )\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjdRzLbN-ANo"
      },
      "source": [
        "#### Long context and token counting\n",
        "\n",
        "Gemini 2.0 Flash and 2.5 Pro have a 1M token context window.\n",
        "\n",
        "In practice, 1 million tokens could look like:\n",
        "\n",
        "- 50,000 lines of code (with the standard 80 characters per line)\n",
        "- All the text messages you have sent in the last 5 years\n",
        "- 8 average length English novels\n",
        "- 1 hour of video data\n",
        "\n",
        "Let's feed in an entire book and ask questions:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "b6pGhOkj-CFS"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "res = requests.get(\"https://gutenberg.org/cache/epub/16317/pg16317.txt\")\n",
        "book = res.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "C0nnKaKC-NMu",
        "outputId": "db03bfbd-13a0-4b5f-b935-c9710ce49ed6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ï»¿The Project Gutenberg eBook of The Art of Public Speaking\r\n",
            "    \r\n",
            "This ebook is for the use of anyon\n"
          ]
        }
      ],
      "source": [
        "print(book[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ves9N2m-_k-V",
        "outputId": "016f9d01-7084-4a7d-fb40-9ed2d672c1cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# charakters 979714\n",
            "# words 162461\n",
            "# tokens: ~216614\n"
          ]
        }
      ],
      "source": [
        "print(f\"# charakters {len(book)}\")\n",
        "print(f\"# words {len(book.split())}\")\n",
        "print(f\"# tokens: ~{int(len(book.split()) * 4/3)}\")   # rule of thumb: 100tokens=75words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "6hmtD77wMXdF",
        "outputId": "aabe347f-4af6-44ad-ffe0-7ad11892ea37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a summary of \"The Art of Public Speaking\" in 10 bullet points:\n",
            "\n",
            "*   **Focus on the Speaker:** The book emphasizes that effective public speaking comes from within, focusing on self-development and having something meaningful to say.\n",
            "*   **Conquering Fear:** Provides practical advice on overcoming stage fright, primarily by focusing on the subject matter and preparation.\n",
            "*   **Variety is Key:** Monotony is identified as the cardinal sin of public speaking, stressing the importance of vocal variety, emphasis, and pacing.\n",
            "*   **Emphasis and Subordination:** Highlights the need to strategically emphasize important words and subordinate unimportant ones for clarity and impact.\n",
            "*   **Vocal Dynamics:** Vocal Dynamics: Covers change of pitch, change of pace, pauses, and inflection to enhance expressiveness and engagement.\n",
            "*   **Pause and Effect:** Utilizes the potent tool of the pause, showing different ways you can use a pause to make a speech more effective.\n",
            "*   **Power in Concentration:** Stresses that speaking, and getting across the message, is the top priority for a speaker.\n",
            "*   **Use Force Wisely:** Emphasizes feeling in addition to physical force or strength.\n",
            "*   **Ethos Matters:** Advocates for developing a strong and sympathetic character to connect genuinely with the audience and build enthusiasm.\n",
            "*   **Delivery Methods:** Touches on the four methods of delivery: Reading from Manuscript, Speaking from Memory, Speaking from Notes, and Extemporaneous Speech.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "summarise the book.Return 10 bullet points/\n",
        "\n",
        "{book}\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL ,\n",
        "    contents=prompt,\n",
        ")\n",
        "\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt9NUCaexPqy"
      },
      "source": [
        "To understand the token usage, you can check `usage_metadata`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "6LAoNQ3Ys-CB",
        "outputId": "cdbd1529-ca37-4f22-9e00-e7100dcde555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'GenerateContentResponse' object has no attribute 'usage_metadeta'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-68cdf563dc92>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musage_metadeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidates_token_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musage_metadeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_token_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musage_metadeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_token_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    992\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m                         \u001b[0;31m# this is the current error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{type(self).__name__!r} object has no attribute {item!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GenerateContentResponse' object has no attribute 'usage_metadeta'"
          ]
        }
      ],
      "source": [
        "print(response.usage_metadeta.candidates_token_count)\n",
        "print(response.usage_metadeta.prompt_token_count)\n",
        "print(response.usage_metadeta.total_token_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jzrjfNDxUhZ"
      },
      "source": [
        "You can also use `count_tokens` to check the size of your input prompt(s):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "EIrVpB-Htc3y",
        "outputId": "dc44a29f-6484-499d-d3c5-bdcb19095e14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountTokensResponse(total_tokens=250554, cached_content_token_count=None)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "client.models.count_tokens(model=MODEL,contents=prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE7MEKBI18K0"
      },
      "source": [
        "## !! Exercise: Chat with a book !!\n",
        "\n",
        "Task:\n",
        "- Create a chat\n",
        "- Use a system prompt: `\"You are an expert book reviewer with a witty tone.\"`\n",
        "- Use a temperature of `1.5`\n",
        "- Ask 1 to summarize the book\n",
        "- Ask 1 question to explain more detail about a certain topic from the book\n",
        "- Ask to create a social media post based on the book\n",
        "- Print the total number of tokens used during the chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "sKL0JNbCzY0P",
        "outputId": "95809297-f9ea-48c3-ffc3-3c8e892b16ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's wonderful! What kind of dogs do you have? Tell me a little more about them! I'd love to hear their names, breeds, and anything else you'd like to share. ðŸ˜Š\n",
            "\n"
          ]
        }
      ],
      "source": [
        "chat=client.chats.create(model=MODEL,\n",
        "                         config=types.GenerateContentConfig(\n",
        "                             temperature=1.5,\n",
        "                             system_instruction =\"You are an expert book reviewer with a witty tone.\")\n",
        "\n",
        "                         )\n",
        "\n",
        "response == chat.send_message(prompt)\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\"explain more about infection\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "K5GHTwq-tm0S",
        "outputId": "dd862c99-5a60-40e4-b0b2-9531f3b86562",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, let's dive deeper into inflectionâ€”that vocal dance of rising and falling tones within wordsâ€”but let's ditch the boring definition and talk about it in a way that sticks.\n",
            "\n",
            "**Think of inflection as the emotional GPS in your voice:**\n",
            " \n",
            "Imagine your voice is a tiny rollercoaster going through the land of your words. Inflection is how the tracks twist and turn:\n",
            " \n",
            "*   **Rising Track:** Suspicion, Question. \"You're going...where?\n",
            "*   **Level Track:** Confidence and even tone. \"I see...where we're going is there. (This isn't wrong just rarely interesting.)\n",
            "*   **Downing Track:** Assurity, Authority. \"I Know Where To Go.\"\n",
            "\n",
            "**Inflection = meaning and emotional direction.**\n",
            "A quick way to understand infection in music is to imagine there are only a few songs on offer to play in the mood and situation. Is that better than nothing? Then is someone who reads from music with all the information they were trained better or not? That is a difficult question, and that's the question you answer when someone questions the need for your words - by intonation - in the world of performance and speech.\n",
            "\n",
            "But here's the kicker: *It's subtle* . Overdo it and you're now a \"soap opera queen,\" a characature. Don't do enough, and your words fall dead at the audience's feet (they take nothing, give nothing in return.)\n",
            "\n",
            "Let's say that your message is, \"That's Fine\". This sounds very neutral...how will you make it different? You get:\n",
            " \n",
            "1.    **Fine:** In short you can go for the *low notes that signal sarcasm and suspicion.* This means \"no that's bad.\" This will sound more cutting the lower your sound gets as you trail the word...but know it sounds uncooperative and hostile if not managed well.\n",
            " 2.    **Fi-ine?**: Here is where we do something with a *rise up at the tail end of the work to indicate you're wondering.* Or perhaps asking, but probably to ask if that's okay to make plans in advance.\n",
            "  3.   **THAT'S fine:** There, at all times remember not to focus on any one element to use emphasis to your needs (it changes with every possible element that can use it) And we remember from here it's possible to mean that your approval or approval with force has no limit. \n",
            "All different, All with more than one thing said by three words...all of a sudden the key of sound has so much more it adds! \n",
            "\n",
            "Is \"inflection and variety of vocal delivery always the key to public delivery. Well...a quick lesson in music from some classical training might benefit people in that discussion so they understood key signatures (all are just the right things placed in another form, at all different places with certain arrangements), for the voice too is a range and an entire signature to play upon at your own device! But in some, we need not more range but also good advice so it's right or interesting at all for the work in our hands. You must believe so when you speak the language, not think it or want it.\n",
            "\n",
            "Now if you know all those elements (that will help your brain, not you the next time your voice shakes like a bowl of jelly)...the trick there is \"do NOT focus, go for that sweet sauce called soul, or if you prefer emotion. You will give life, it won't control like it's something alien. Then let all come out to tell the people who's made, with your words from brain, life and a body.\n",
            "\n",
            "**Okay let's test:** Here's a quote: \"Well...if that is so...then why.\"\n",
            "There's a great sense of wonder here, many keys and emotions can flow...make me one that is curious, yet almost angry to the thing you may have just witnessed...a great twist. (Or tell me more as desired.)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muzBsZi5Fmgs"
      },
      "source": [
        "## Recap & Next steps\n",
        "\n",
        "Nice work! You learned\n",
        "- Python SDK quickstart\n",
        "- Text prompting\n",
        "- Streaming and chats\n",
        "- System prompts and config options\n",
        "- Long context and token counting\n",
        "\n",
        "\n",
        "More helpful resources:\n",
        "- [API docs quickstart](https://ai.google.dev/gemini-api/docs/quickstart?lang=python)\n",
        "- [Text generation docs](https://ai.google.dev/gemini-api/docs/text-generation)\n",
        "- [Long context docs](https://ai.google.dev/gemini-api/docs/long-context)\n",
        "\n",
        "Next steps:\n",
        "- [Part 2: Multimodal understanding (image, video, audio, docs, code)](https://github.com/patrickloeber/workshop-build-with-gemini/blob/main/notebooks/part-2-multimodal-understanding.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1GWRZV5gqzC"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6pzNgQHJtkxc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}